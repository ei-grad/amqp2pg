#!/usr/bin/env python
# encoding: utf-8

from cStringIO import StringIO
from time import time, sleep
import argparse
import csv
import logging
import sys

import psycopg2
import pika


logger = logging.getLogger(__name__)


class Amqp2Pg(object):

    def __init__(self, args):
        self.args = args
        self.converter = getattr(__import__(args.converters_pkg), args.converter).convert
        self.last_flush = time()
        self.messages = []

    def db_connect(self):
        return psycopg2.connect(
            host=self.args.db_host, port=self.args.db_port,
            database=self.args.database,
            user=self.args.db_user, password=self.args.db_passwd
        )

    def main(self):
        while True:
            try:
                self.db = self.db_connect()
                self.conn = pika.SelectConnection(pika.ConnectionParameters(
                    self.args.rq_host, self.args.rq_port, self.args.rq_vhost,
                    credentials=pika.PlainCredentials(self.args.rq_user, self.args.rq_passwd),
                ), on_open_callback=lambda conn: conn.channel(on_open_callback=self.on_ch_open))
                self.conn.ioloop.start()
            except KeyboardInterrupt:
                logger.info("Terminating!")
                # rollback in case if got exception in the flush
                self.db.rollback()
                self.flush(True)
                self.conn.close()
                self.conn.ioloop.start()
                break
            except:
                logger.error("Restarting main loop in 5 sec...", exc_info=True)
                self.messages = []  # we have to forget all messages from old rabbit connection
                try:
                    if not self.conn.is_closed:
                        self.conn.close()
                        self.conn.ioloop.start()
                except:
                    pass
                try:
                    self.db.close()
                except:
                    pass
                sleep(5.)

    def on_ch_open(self, ch):

        self.ch = ch

        if self.args.rq_qos:
            ch.basic_qos(logger.debug, prefetch_count=self.args.max_size * 2)

        ch.queue_declare(logger.debug, queue=args.queue, durable=True)

        if self.args.rq_bind:
            exch, routing_key = self.args.rq_bind
            ch.queue_bind(queue=self.queue, exchange=exch, routing_key=routing_key)

        logger.info("Ready to consume messages!")

        ch.basic_consume(self.on_message, queue=self.args.queue)

        self.periodic_flush()

    def on_message(self, ch, frame, header, body):
        self.messages.append((body, frame.delivery_tag))
        if len(self.messages) >= self.args.max_size:
            self.flush()

    def add_timeout(self, delay, cb):
        self.conn.ioloop.add_timeout(delay, cb)

    def periodic_flush(self):
        if self.messages and time() - self.last_flush > self.args.max_wait:
            self.flush()
        self.add_timeout(1., self.periodic_flush)

    def flush(self, flush_all=False):

        self.last_flush = time()

        buf = StringIO()
        w = csv.writer(buf)
        chunk = self.messages[:self.args.max_size]
        columns, data = self.converter.convert_raws(
            # tag is used for basic_ack below!
            [row for row, tag in chunk]
        )
        w.writerows(data)
        buf.seek(0)
        c = self.db.cursor()
        c.copy_expert("COPY {table} ({columns}) FROM STDIN CSV".format(
            table=self.args.table,
            columns=', '.join(columns),
        ), buf)
        c.close()
        self.db.commit()
        del self.messages[:self.args.max_size]
        self.ch.basic_ack(delivery_tag=tag, multiple=True)
        logger.info("Wrote %d rows in %.3f sec.", len(data), time() - self.last_flush)


if __name__ == "__main__":

    parser = argparse.ArgumentParser(formatter_class=argparse.RawDescriptionHelpFormatter)

    parser.add_argument("--converter", required=True, help=u"Какой конвертер использовать")
    parser.add_argument("--converters-pkg", default='amqp2pg_conv', help=u"Имя пакета с конвертерами")
    parser.add_argument("--database", required=True, help=u"Имя БД")
    parser.add_argument("--table", required=True, help=u"Имя таблицы")
    parser.add_argument("--queue", required=True, help=u"RabbitMQ queue to consume")
    parser.add_argument("--max-size", default=5000, type=int,
                        help=u"Max messages count to write in single transaction")
    parser.add_argument("--max-wait", default=1., type=float,
                        help=u"Max time to wait to flush pending messages")

    db_args = parser.add_argument_group("Database", u"Параметры базы данных")
    db_args.add_argument("--db-host", help=u"Хост")
    db_args.add_argument("--db-port", type=int, help=u"Порт")
    db_args.add_argument("--db-user", help=u"Пользователь")
    db_args.add_argument("--db-passwd", help=u"Пароль")

    rq_args = parser.add_argument_group(
        u"RabbitMQ",
        u"Параметры подключения к RabbitMQ для отправки сообщений"
    )
    rq_args.add_argument("--rq-host", default="127.0.0.1",  help=u"RabbitMQ host")
    rq_args.add_argument("--rq-port", default=5672,         help=u"RabbitMQ port")
    rq_args.add_argument("--rq-user", default="guest",      help=u"RabbitMQ user")
    rq_args.add_argument("--rq-passwd", default="guest",    help=u"RabbitMQ password")
    rq_args.add_argument("--rq-vhost", default="/",         help=u"RabbitMQ virtual host")
    rq_args.add_argument("--rq-qos", type=int,              help=u"RabbitMQ use basic_qos")
    rq_args.add_argument("--rq-bind", nargs=2, metavar=('EXCHANGE', 'ROUTING_KEY'),
                         help=u"Bind queue to the specified exchange (optional)")

    parser.add_argument("--log-file", help=u"Имя лог файла (если не указано - логи пишутся в stderr)")
    parser.add_argument("--log-level", default='INFO',
                        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
                        help=u"Уровень логгирования")

    parser.add_argument("--syslog", help=u"Хост куда отправлять логи Syslog")
    parser.add_argument("--syslog-level", default='INFO',
                        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
                        help=u"Уровень логгирования в Syslog")

    args = parser.parse_args()

    log_level = getattr(logging, args.log_level)

    root_logger = logging.getLogger()

    if args.log_file:
        log_handler = logging.handlers.TimedRotatingFileHandler(args.log_file)
        log_handler.setFormatter(logging.Formatter(
            u'%(asctime)s %(levelname)8s %(funcName)s:%(lineno)d %(message)s'
        ))
        log_handler.setLevel(log_level)
        root_logger.addHandler(log_handler)
        root_logger.setLevel(log_level)
    else:
        logging.basicConfig(
            format=u'%(asctime)s.%(msecs).3d %(levelname)8s %(module)6s:%(lineno)03d %(message)s',
            level=log_level, datefmt="%Y-%m-%d %H:%M:%S"
        )

    if args.syslog:
        syslog_handler = logging.handlers.SysLogHandler((args.syslog, 514))
        syslog_handler.setFormatter(logging.Formatter(
            sys.argv[0] + u'[%(process)s]: %(levelname)8s %(module)s:%(lineno)d %(message)s'
        ))
        syslog_handler.setLevel(getattr(logging, args.syslog_level))
        root_logger.addHandler(syslog_handler)

    Amqp2Pg(args).main()
